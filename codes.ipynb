{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from scipy import spatial\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tensorflow.keras import layers, Model\n",
    "from lib.load import *\n",
    "from lib.extractor import ImgExtractor\n",
    "from lib.model import build_model\n",
    "\n",
    "from PIL import Image, ImageEnhance, ImageOps\n",
    "\n",
    "tf.config.experimental_run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S0: Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images = load_real_images('Dataset/Real_Effusion')\n",
    "synthetic_images = load_synthetic_images('Dataset/Synthetic_Effusion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S1: Extract Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: Prepare images arr into model input format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 224, 224, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realImgMIArr = np.squeeze(np.array(real_images[0]))\n",
    "realImgMIArr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 224, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synImgMIArr = np.squeeze(np.array(synthetic_images[0]))\n",
    "synImgMIArr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Use pretrained VGG16 model to extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = ImgExtractor(model=\"VGG16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "realExtFea = extractor.model.predict(realImgMIArr)\n",
    "synExtFea = extractor.model.predict(synImgMIArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(352, 1000) (170, 1000)\n"
     ]
    }
   ],
   "source": [
    "print(realExtFea.shape, synExtFea.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Append Extracted feature to current list\n",
    "\n",
    "- real_images is a list has 3 element -> 1: raw arr 2: file names 3: extracted features\n",
    "- synthetic_images is a list has 4 element -> 1: raw arr 2: folder name 3: file name 4: extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images.append(realExtFea)\n",
    "synthetic_images.append(synExtFea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S2: Compare similarity Score\n",
    "\n",
    "- 两两对比: 利用index 循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "simi_record = []\n",
    "for r_index in range(len(real_images[0])):\n",
    "    for s_index in range(len(synthetic_images[0])):\n",
    "        r_fea = real_images[2][r_index]\n",
    "        s_fea = synthetic_images[3][s_index]\n",
    "        \n",
    "        # cal similarity + record real path + record syn path\n",
    "        simi_score = cosine_similarity(r_fea.reshape(1, -1), s_fea.reshape(1, -1))[0][0]\n",
    "        r_path = real_images[1][r_index]\n",
    "        s_path = synthetic_images[1][s_index] + \"/\" + synthetic_images[2][s_index]\n",
    "        \n",
    "        r_rawArr = real_images[0][r_index]\n",
    "        s_rawArr = synthetic_images[0][s_index]\n",
    "        \n",
    "        simi_record.append([r_path, s_path, simi_score, r_rawArr, s_rawArr])\n",
    "simiDF = pd.DataFrame(simi_record, columns=[\"realPath\", \"synPath\", \"simiScore\", \"rRawArr\", \"sRawArr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete data to save memory\n",
    "del simi_record\n",
    "del real_images\n",
    "del synthetic_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>realPath</th>\n",
       "      <th>synPath</th>\n",
       "      <th>simiScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m7138_a7356_s7425_1_27_US_.png</td>\n",
       "      <td>d12/1.png</td>\n",
       "      <td>0.040130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m7138_a7356_s7425_1_27_US_.png</td>\n",
       "      <td>za14/1.png</td>\n",
       "      <td>0.435857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m7138_a7356_s7425_1_27_US_.png</td>\n",
       "      <td>za13/1.png</td>\n",
       "      <td>0.390371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m7138_a7356_s7425_1_27_US_.png</td>\n",
       "      <td>d15/1.png</td>\n",
       "      <td>0.314453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m7138_a7356_s7425_1_27_US_.png</td>\n",
       "      <td>z3/1.png</td>\n",
       "      <td>0.325425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         realPath     synPath  simiScore\n",
       "0  m7138_a7356_s7425_1_27_US_.png   d12/1.png   0.040130\n",
       "1  m7138_a7356_s7425_1_27_US_.png  za14/1.png   0.435857\n",
       "2  m7138_a7356_s7425_1_27_US_.png  za13/1.png   0.390371\n",
       "3  m7138_a7356_s7425_1_27_US_.png   d15/1.png   0.314453\n",
       "4  m7138_a7356_s7425_1_27_US_.png    z3/1.png   0.325425"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simiDF.iloc[:5, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3: Build MI datasets based on simi Score\n",
    "\n",
    "- 分档: \n",
    "    - 0.34 - 1\n",
    "    - 0.14 - 0.34\n",
    "    - 0.14 - 0.04\n",
    "    - 0.04 - 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mi(simiDF, lowB, upB):\n",
    "    return simiDF.query(f\"{lowB} <= simiScore <= {upB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    59840.000000\n",
       "mean         0.225467\n",
       "std          0.227435\n",
       "min          0.000015\n",
       "25%          0.043149\n",
       "50%          0.145323\n",
       "75%          0.343558\n",
       "max          0.994263\n",
       "Name: simiScore, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simiDF[\"simiScore\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF1 = build_mi(simiDF, 0.34, 1)\n",
    "trainDF2 = build_mi(simiDF, 0.14, 0.34)\n",
    "trainDF3 = build_mi(simiDF, 0.04, 0.14)\n",
    "trainDF4 = build_mi(simiDF, 0, 0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15140, 5) (15324, 5) (15037, 5) (14339, 5)\n"
     ]
    }
   ],
   "source": [
    "print(trainDF1.shape, trainDF2.shape, trainDF3.shape, trainDF4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S4: Train model to compare accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsModel = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 TrainDF1 as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 class, posArr is X , posLabel is Y\n",
    "posArr = np.array(trainDF1.iloc[:, 3].tolist())\n",
    "negArr = np.array(trainDF1.iloc[:, 4].tolist())\n",
    "\n",
    "posLabel = np.array([0, 1] * len(posArr)).reshape(-1, 2)\n",
    "negLabel = np.array([1, 0] * len(negArr)).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       ...,\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posLabel\n",
    "negLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "posArr = np.squeeze(posArr)\n",
    "negArr = np.squeeze(negArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15140, 224, 224, 3) (15140, 224, 224, 3) (15140, 2) (15140, 2)\n"
     ]
    }
   ],
   "source": [
    "print(posArr.shape, negArr.shape, posLabel.shape, negLabel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30280, 224, 224, 3) (30280, 2)\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate([posArr, negArr])\n",
    "y = np.concatenate([posLabel, negLabel])\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train model, 400 data as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 224, 224, 3) (400, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X[:400].shape, y[:400].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 250s 54s/step - loss: 0.7266 - accuracy: 0.5300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7f85b55460>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# epochs define how many times you train the model\n",
    "clsModel.fit(X[:400], y[:400], batch_size = batch_size, verbose = 1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 62s 5s/step - loss: 0.6534 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.653351366519928, 1.0]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss, accuracy = clsModel.evaluate(X[:400], y[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Into module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss: 求导更新参数用的: squareloss:  y_true, y_prd, 1, 0.8 -> (1 - 0.8)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 class, posArr is X , posLabel is Y\n",
    "def cal_accuray_for_trainDF(trainDF, epochs=10):\n",
    "    posArr = np.array(trainDF.iloc[:, 3].tolist())\n",
    "    negArr = np.array(trainDF.iloc[:, 4].tolist())\n",
    "    # 0 class\n",
    "    posLabel = np.array([0, 1] * len(posArr)).reshape(-1, 2)\n",
    "    negLabel = np.array([1, 0] * len(negArr)).reshape(-1, 2)\n",
    "\n",
    "    posArr = np.squeeze(posArr)\n",
    "    negArr = np.squeeze(negArr)\n",
    "\n",
    "    X = np.concatenate([posArr, negArr])\n",
    "    y = np.concatenate([posLabel, negLabel])\n",
    "\n",
    "    clsModel.fit(X, y, batch_size = 128, verbose = 1, epochs=epochs)\n",
    "    loss, accuracy = clsModel.evaluate(X, y)\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Test sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleDF = trainDF1.sample(20)\n",
    "sampleDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 5/79 [>.............................] - ETA: 1:44:56 - loss: 0.7296 - accuracy: 0.5000"
     ]
    }
   ],
   "source": [
    "loss, accuracy = cal_accuray_for_trainDF(trainDF1.sample(5000), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
